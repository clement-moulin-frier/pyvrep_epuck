{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical session 4: Modulating internal states and Sensing other robot's attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last practical session, we saw how to run multiple behaviors in parallel on multiple robots. In this section we will see more advanced methods for combining behaviors by modulating their activations according to internal states of the robot and by allowing them to sense the attributes of others. In order to start with a clean basis, let's first provide the definition of several behaviors. These four behaviors are simply implementations of the [Braitenberg vehicles](https://docs.google.com/presentation/d/1FlAUyvNynYU4mDBE2o20pf2Bn5PC_9Id3SK8sCMfr-Q/edit#slide=id.g31e1b425a3_0_0) we have seen in class, where the sources (i.e. what is sensed by the proximeters) are other epucks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fear(robot):\n",
    "    left, right = robot.prox_activations(tracked_objects=[\"ePuck\"])\n",
    "    left_wheel = left\n",
    "    right_wheel = right\n",
    "    return left_wheel, right_wheel\n",
    "\n",
    "def aggression(robot):\n",
    "    left, right = robot.prox_activations(tracked_objects=[\"ePuck\"])\n",
    "    left_wheel = right\n",
    "    right_wheel = left\n",
    "    return left_wheel, right_wheel\n",
    "\n",
    "def love_cuddly(robot):\n",
    "    left, right = robot.prox_activations(tracked_objects=[\"ePuck\"])\n",
    "    left_wheel = 1 - left\n",
    "    right_wheel = 1 - right   \n",
    "    return left_wheel, right_wheel\n",
    "\n",
    "def love_shy(robot):\n",
    "    left, right = robot.prox_activations(tracked_objects=[\"ePuck\"])\n",
    "    left_wheel = 1 - right\n",
    "    right_wheel = 1 - left   \n",
    "    return left_wheel, right_wheel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the arguments of the behavior functions above are now named `robot`, whereas they were named `epuck`in the previous sessions. This is actually strictly equivalent, the argument name being an arbitrary name. We choose here to call it `robot` in order to avoid a confusion when dealing with multiple epucks. The only important thing is that you use the same name in the function body (i.e `robot` here)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a fifth behavior for obstacle avoidance, where obstacles are walls, pilars, trees and cups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def obstacle_avoidance(robot):\n",
    "    left, right = robot.prox_activations(tracked_objects=[\"20cm\", \"Tree\", \"Cup\"])\n",
    "    left_wheel = 1 - right\n",
    "    right_wheel = 1 - left   \n",
    "    return left_wheel, right_wheel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open V-REP and load the scene `epuck-scene-4.ttt` located in the directory `robotics/pyvrep_epuck/vrep-scenes`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reminder:** First import the functions `open_session` and `close_session`. Then, obtain a reference to the simulator and the E-Puck by calling `open_session`. Since there are three epucks in the scene, we call it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulator_interface import open_session, close_session\n",
    "simulator, epuck1, epuck2, epuck3 = open_session(n_epucks=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then execute the code you will encounter in the notebook or the code you will write for answering the questions. Whenever you want to restart from scratch (e.g. because something goes wrong or because you want to restart from scratch), first close the session by executing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_session(simulator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will properly close all the running processes. Then restart the notebook (`Kernel -> Restart`) and open the session again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulator_interface import open_session, close_session\n",
    "simulator, epuck1, epuck2, epuck3 = open_session(n_epucks=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you will restart with a clean session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emergent behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running one or several behaviors on a robot, you might observe behavioral responses that are not present in any of the behavior definitions. This usually doesn't mean that there is a bug, it could just be the result of an emergent behavioral property. Let's analyze this on a quick example, by running the `obstacle_avoidance` behavior on each epuck:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Behavior obstacle_avoidance started\n",
      "Behavior obstacle_avoidance started\n",
      "Behavior obstacle_avoidance started\n"
     ]
    }
   ],
   "source": [
    "for e in simulator.robots:\n",
    "    e.attach_behavior(obstacle_avoidance, freq=10)\n",
    "    e.start_all_behaviors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the cell above is a shortcut to execute the same set of instructions (the indented lines) on all the robots returned by the `open_session` function (the one you use to connect to the simulator). It can become very useful when you want to run the same set of instructions on all the robots, as it is the case here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1:** You will observe that the ePucks seem to be attracted to objects that are not handled by the behavior (e.g. other ePucks). Analyse this phenomena and explain below why it is occuring in a few lines:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Double click on this cell to enter your answer*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing robot interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyze the interaction between two robots that run different behaviors. First close the current session and open a new one with only two epucks that will be controlled (the third epuck is still part of the scene but we don't need it here):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_session(simulator, epuck1, epuck2, epuck3)\n",
    "simulator, epuck1, epuck2 = open_session(n_epucks=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2:** In addition to the `obstacle_avoidance` behavior, run several combinations of the four other behaviors defined above. For example, run `obstacle_avoidance` and `fear` on `epuck1` ; and `obstacle_avoidance` and `aggression` on `epuck2`. Find two of these combinations that you consider as interesting (e.g. because they result in a relatively complex interaction pattern, or because they can be linked to animal behavior) and describe them in a few lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighting behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen in the previous session, it is possible to run several behaviors in parallel on the same robot. When doing it, the motor activation sent to each wheel corresponds to the average of the motor activation returned by each behavior (this averaging is implemented internally, you don't need to worry about it). \n",
    "\n",
    "It is also possible to specify the weight of each running behavior, i.e. how much it will count in the averaging. This is done by returning three values in the function defining a behavior (instead of two as we were doing until now: one for the left wheel activation and one for the right one). For example, if we want to run the `obstacle_avoidance` behavior with a weight of 1 and the `fear` behavior with a weight of 0.5, we write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Behavior fear started\n",
      "Behavior obstacle_avoidance started\n",
      "Behavior fear started\n",
      "Behavior obstacle_avoidance started\n"
     ]
    }
   ],
   "source": [
    "# First detach all behaviors on both robots:\n",
    "for e in simulator.robots:\n",
    "    e.detach_all_behaviors()\n",
    "    e.stop()\n",
    "    \n",
    "# define the obstacle_avoidance behavior with a weight of 1. This is indicated by the third value returned by the function:\n",
    "def obstacle_avoidance(robot):\n",
    "    left, right = robot.prox_activations(tracked_objects=[\"20cm\", \"Tree\", \"Cup\"])\n",
    "    # The weight associated with this behavior is the third returned value, here 1:\n",
    "    return 1 - right, 1 - left , 1.\n",
    "\n",
    "# define the fear behavior with a weight of 0.5. This is indicated by the third value returned by the function:\n",
    "def fear(robot):\n",
    "    left, right = robot.prox_activations(tracked_objects=[\"ePuck\"])\n",
    "    # The weight associate with this behavior is the third return value, here 0.5:\n",
    "    return left, right, 0.5\n",
    "\n",
    "# Attach and start both behaviors on both robots:\n",
    "for e in simulator.robots:\n",
    "    e.attach_behavior(obstacle_avoidance, freq=10)\n",
    "    e.attach_behavior(fear, freq=10)\n",
    "    e.start_all_behaviors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By doing this, the wheel activations returned by the `obstacle_avoidance` behavior will have twice more weight than those returned by the `fear` behavior. For example, if `obstacle_avoidance` returns 0.6 for the left wheel, and `fear` returns 0.9, then the total activation of that wheel will be $(0.6 * 1 + 0.9 * 0.5) / (1 + 0.5) = 0.7$ (i.e. the average of both values weighted by their respective activation). Note that when no weight is provided in a behavior definition (i.e. when the behavior function returns only two values as usual), the corresponding behavior is set with a default weight of one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighting behaviors according to internal states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This weighting is particularly useful to activate a behavior according to some internal states of the robot. Let's consider a robot that eats spheres (as in the previous session) and that eating those spheres allows to raise a simulated energy level of the robot. We want to continuously compute the energy level of the robot according to how much spheres it has recently eaten. To do so, we first need a way to know when a robot eats a sphere. This is done by executing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epuck1.has_eaten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above return `True` if the robot (`epuck1` here) has eaten a sphere since the last call of the function. Run both the `obstacle avoidance` and the `foraging` behavior on an ePuck and execute the `has_eaten` function above at different times to understand correctly how it works. Remember we have already defined a `foraging_behavior` in the last session, which can be implemented like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def foraging(robot):\n",
    "    left, right = robot.prox_activations(tracked_objects=[\"Sphere\"])\n",
    "    left_activation = right\n",
    "    right_activation = left\n",
    "    return left_activation, right_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First start sphere apparition in the environment:\n",
    "simulator.start_sphere_apparition(period=10)\n",
    "\n",
    "# Detach all existing behaviors, and attach then start obstacle_avoidance and foraging on all robots:\n",
    "for e in simulator.robots:\n",
    "    e.detach_all_behaviors()\n",
    "    \n",
    "    e.attach_behavior(obstacle_avoidance, freq=10)\n",
    "    e.attach_behavior(foraging, freq=10)\n",
    "    e.start_all_behaviors()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to continuously compute the energy level of a robot, so that the level decreases slowly when nothing is eaten and increases whenever food is consumed. This can be done by attaching and starting a *routine* to a robot. The definition of a routine is very similar to the definition of a behavior, except that it doesn't return any value (whereas a behavior always returns the left and right wheel activations, and optionally a weight). Thus, a routine corresponds to a set of instructions that are executed at a particular frequency (as in a behavior), e.g. to compute some robot's internal states according to its interaction with the environment.\n",
    "\n",
    "Let's define a routine called `foraging_drive` that computes the energy level as specified above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def foraging_drive(robot): \n",
    "    if robot.has_eaten():\n",
    "        robot.energy_level += 0.2  # if the robot has eaten a sphere, increase its energy level by 0.2\n",
    "    else:\n",
    "        robot.energy_level -= 0.01  # otherwise (nothing eaten), decrease the energy level by 0.01\n",
    "    # The line below bounds the value of the energy level between 0 and 1\n",
    "    robot.energy_level = min(1., max(robot.energy_level, 0.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for a behavior, the function defining a routine takes a `robot` as an argument representing the ePuck on which the routine is attached. Attaching a routine is done with: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epuck1.attach_routine(foraging_drive, freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for a behavior, a routine is attached to an epuck at a given frequency. However, contrary to behaviors, routines are not directly involved in motor control and therefore can be run at a lower frequency (1Hz above). The code of the `foraging_drive` function above will be executed each second (1Hz frequency), consequently modulating the ePuck energy level stored in `robot.energy_level` according to how good the robot is at catching spheres.\n",
    "\n",
    "Before starting a routine, we need to define an initial level of energy. Let's do it on `epuck1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epuck1.energy_level = 0.5  # Note that the energy level is bounded between 0 and 1 in the foraging_drive function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is mandatory because `energy_level` is incremented or decremented in the `foraging_drive` definition. If not initialized, it will throw an error.\n",
    "\n",
    "Let's now effectively start this routine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routine foraging_drive started\n"
     ]
    }
   ],
   "source": [
    "epuck1.start_routine(foraging_drive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And check the evolution of the energy level in `epuck_1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epuck1.energy_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the robot behave in the environment and re-execute the cell above to track the evolution of the energy level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3:** Modify the `foraging` behavior so that it is weighted according to the energy level of the robot: the lower the energy level, the higher `foraging` is weighted. However, as seen in Q1 above, the ePuck might still be attracted to spheres even when the `foraging` weight is null. Solve this issue by adding another behavior that drives the robot away from sphere according to the energy level: the higher the energy level, the more the robot is repulsed from spheres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensing other robot's attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be useful to allow a robot to sense attributes from other robots. For example, one might want to define different species of robot (cats and mouses for example) so that how a robot interact with another depends on their respective species. To achieve this, it is **not** recommended to modify the ePuck labels directly in V-REP (as a general rule, never modify the object labels in the VREP scene). Instead, each robot can be set with a specific attribute, e.g `epuck.species = \"cat\"` and that attribute can be sensed by other robots whenever it is detected by a proximeter. Let's try it with three epucks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "close_session(simulator)\n",
    "simulator, epuck1, epuck2, epuck3 = open_session(n_epucks=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where we define a `species` attribute for each robot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epuck1.species = \"cat\"\n",
    "epuck2.species = \"mouse\"\n",
    "epuck3.species = \"mouse\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have one cat and two mouses. Place the robots so that `epuck3` (mouse) is sensing `epuck1` (cat) on its left proximeter and `epuck2` (mouse) on its right proximeter. One can access attributes of sensed epucks by first executing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(left, right), (epuck_left, epuck_right) = epuck3.prox_activations(tracked_objects=[\"ePuck\"], return_epucks=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell above calls the `prox_activations` function of `epuck3` with an additional argument, `return_epucks`, which is set to `True`. When called like this, `prox_activations` will return the left and right proximeter activations as usual, as well as the references to the epucks that are sensed by the proximeters, if any. Then we can access a specific attribute of those ePucks by executing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_species, right_species = epuck3.sensed_epuck_attributes(epuck_left, epuck_right, \"species\", default_value=\"none\")\n",
    "\n",
    "print(left_species)\n",
    "print(right_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sensed_epuck_attributes` function takes 4 arguments: the epuck sensed by the left proximeter (called `epuck_left` in the example above), the one sensed by the right proximeter (called `epuck_right` above), the name of the attribute we are interested in (here `\"species\"`) and the default value to return if a proximeter is not sensing any ePuck (here `none`).\n",
    "\n",
    "Move the robots in the scene and check how the attribute sensing is changing accordingly by re-executing the two above cells. Then try with other attributes, for example by setting a `age` attribute to the robots and sensing it from the proximeters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now extend the `fear` behavior so that mouses are only afraid by the cat but not by the other mouse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fear(robot):\n",
    "    # call prox_activation with return_epucks set to True:\n",
    "    (left, right), (epuck_left, epuck_right) = robot.prox_activations(tracked_objects=[\"ePuck\"], return_epucks=True)\n",
    "    # Retrieve the species attributes of the sensed epucks:\n",
    "    left_species, right_species = robot.sensed_epuck_attributes(epuck_left, epuck_right, \"species\", default_value =\"none\")\n",
    "    # Set the left wheel activation to the value of the left sensor if a cat is on the left. Otherwise set it to 0:\n",
    "    left_activation = left if left_species == \"cat\" else 0\n",
    "    # Set the right wheel activation to the value of the right sensor if a cat is on the right. Otherwise set it to 0:\n",
    "    right_activation = right if right_species == \"cat\" else 0\n",
    "    # Return both wheel activation as usual:\n",
    "    return left_activation, right_activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run this behavior together with the `obstacle_avoidance` one on `epuck3`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Behavior obstacle_avoidance started\n",
      "Behavior fear started\n"
     ]
    }
   ],
   "source": [
    "epuck3.behavior_mixer.set_mode(\"average\")\n",
    "epuck3.detach_all_behaviors()\n",
    "epuck3.attach_behavior(obstacle_avoidance, freq=10)\n",
    "epuck3.attach_behavior(fear, freq=10)\n",
    "epuck3.start_all_behaviors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check in the simulator that `epuck3` (mouse) is now avoiding `epuck1` (cat) but not `epuck2` (mouse). We can modify the `species` attribute of robots on the fly. Let's swap the species of `epuck1` and `epuck2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epuck1.species = \"mouse\"\n",
    "epuck2.species = \"cat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check in the simulator that `epuck3` (mouse) is now avoiding `epuck2` (cat) but not `epuck1` (mouse)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4:** Use the new functionalities we have seen in this session to design the following system:\n",
    "Two epucks are equipped with behaviors to avoid obstacle and catch spheres, as well as being attracted or repulsed by the other epuck. Attraction and repulsion depend on the energy level of the other robot: the higher this level the more attraction, the lower this level the more repulsion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for e in simulator.robots:\n",
    "    e.detach_all_behaviors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5**: Modify the previous simulation such that attraction and repulsion depend on how much a robot has been close to others in the recent past. To do so, define a `social_drive` routine that modulates the value of a `social_need` attribute in each robot. This social need continuously increases when other robots are far and decreases when a robot comes closer to its conspecifics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## About the mini-project\n",
    "\n",
    "The aim of the mini project is to show that you have understood all the concepts we have seen during these three practical sessions and that you can integrate them in a single demo. You can of course modify the V-REP scene at your will, e.g adding cups or trees. Don't forget to save you modified V-REP scene (`File -> Save scene as` in V-REP). You can start your project in a new Jupyter Notebook (`File -> New notebook -> Python3`) in the menu bar at the top of this notebook). Use both text cells (explaining what you are doing) and code cells (with the corresponding code to execute).\n",
    "\n",
    "Therefore, your project will consists of two files: a V-REP scene (extension `.ttt`) a Jupyter Notebook (extension `.ipynb`). Don't forget to save them, e.g. on a USB stick, before logging out from the UPF computers. See [this slide](https://docs.google.com/presentation/d/1FlAUyvNynYU4mDBE2o20pf2Bn5PC_9Id3SK8sCMfr-Q/edit#slide=id.g34900c6ead_0_0) for more information on the mini-project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
